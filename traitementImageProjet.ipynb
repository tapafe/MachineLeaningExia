{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Traitement d'image du projet TouNum <br />Livrable 1</center>\n",
    "\n",
    "![cesiLogo.jpg](cesiLogo.jpg)\n",
    "\n",
    "|Auteur|Centre|Modification|\n",
    "|---|---|---|\n",
    "|A. RIGAUT|Arras|2020/12/15|\n",
    "|B. THIBAULT|Arras|2020/12/15|\n",
    "|R. VANCAMP|Arras|2020/12/15|\n",
    "|T. POLY|Arras|2020/12/15|\n",
    "|V. NAESSENS|Arras|2020/12/15|\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "\n",
    "L'entreprise TouNoum nous a chargé de traiter deux jeux d'image l'un bruité et le second flouté. Le but est de rendre les images plus traitables par un algorithme de machine learning.\n",
    "\n",
    "## Jeux de données\n",
    "\n",
    "Dans le dossier Dataset nous avons les deux jeux de données dans deux sous-dossier, Noisy(bruité) et Blurry(flouté).\n",
    "## Explication chargement de fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "from scipy import misc\n",
    "from skimage.io import imread_collection, imsave\n",
    "from skimage import *\n",
    "from skimage.filters import unsharp_mask\n",
    "from skimage.restoration import estimate_sigma #Robust wavelet-based estimator of the (Gaussian) noise standard deviation\n",
    "import cv2\n",
    "\n",
    "\n",
    "#creating a collection with the available images\n",
    "noisy = imread_collection('Noisy/*.jpg')\n",
    "blurry = imread_collection('Blurry/*.jpg')\n",
    "noisyPost = []\n",
    "blurryPost = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Lors de nos phases de tests nous avons utilisé la librairie Scipy. Cette bibliothèque ne permet pas de traiter les images RGB (multicanaux). Il y a donc deux démarches qui se proposaient à nous, passer l'image en niveau de gris ou séparer les canaux RGB pour les traiter indépendamment.\n",
    "\n",
    "Dans un premier temps, nous avons testé de passer d'une image RGB à une image en niveau de gris grâce à la fonction rgb2gray. Celle-ci se base sur la formule:\n",
    "$gray = 0.2989 * redChannel + 0.5870 * greenChannel + 0.1140 * blueChannel$ <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(image):\n",
    "    \"\"\"Transform a polychrome image in a grey image\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : array-like, shape (width, height, channel)\n",
    "        Data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Gray like image. One channel\n",
    "    \"\"\"\n",
    "    r, g, b = image[:,:,0], image[:,:,1], image[:,:,2] #isolate each channel\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b #more detail about this scale: https://en.wikipedia.org/wiki/Grayscale\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'image changé en nuances de gris, nous pouvons appliquer de manière simple et rapide un ensemble de filtre que se soit des matrices ou des fonctions. Cependant, cette méthode fait perdre une caractéristique de l'image, sa couleur. En effet, on imagine assez facilement l'intérêt d'une couleur pour un algorithme de machine learning.\n",
    "\n",
    "De se fait, nous avons testé de traiter les canaux individuellement, avec la fonction splitColor qui nous permet de séparer les trois canaux RGB. Cette fonction récupère l'intégralité des pixels d'un canal de l'image, canal qui est représenté par une dimension du tableau représentatif de l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitColor(image):\n",
    "    \"\"\"Create a tiple witch each channel\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : array-like, shape (width, height, channel)\n",
    "        Data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple (red channel, green channel, blue channel)\n",
    "    \"\"\"\n",
    "    red = image[:, :, 0] #all x and y in channel 0 whose is red\n",
    "    green = image[:, :, 1]\n",
    "    blue = image[:, :, 2]\n",
    "    return(red, green, blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis chacun de ces channels ont été traités dans la fonction noisyTreatment. \n",
    "\n",
    "En possession des différents canaux, nous pouvons appliquer nos filtres sur chacun d'entre eux. Ici, nous appliquons un filtre de Gauss à un canal de notre image d'origine afin de la lisser dans l'objectif de réduire le bruit. Suite à ce traitement, nous appliquons la matrice:\n",
    "$$\\begin{bmatrix} -1 & -1 & -1 \\\\ -1 & 9 & -1 \\\\ -1 & -1 & -1 \\end{bmatrix}$$\n",
    "Celle-ci est l'addition de deux matrices: la matrice identité et la matrice de détection de contour :\n",
    "$$\\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix} + \\begin{bmatrix} -1 & -1 & -1 \\\\ -1 & 8 & -1 \\\\ -1 & -1 & -1 \\end{bmatrix} = \\begin{bmatrix} -1 & -1 & -1 \\\\ -1 & 9 & -1 \\\\ -1 & -1 & -1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisyTreatment(channel):\n",
    "    \"\"\"Create a tuple witch each channel\n",
    "    Parameters\n",
    "    ----------\n",
    "    channel : array-like, shape (width, height, channel)\n",
    "        Data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    array-like, shape (width, height)\n",
    "    \"\"\"\n",
    "    arr = []\n",
    "    \n",
    "    filter0 = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "    for layer in layers:\n",
    "        gauss_denoised = ndimage.gaussian_filter(channel, sigma=2.5)\n",
    "        channelFlou = scipy.ndimage.convolve(gauss_denoised, filter0)\n",
    "        result = channel + (channel - channelFlou) * 1\n",
    "        arr.append(result)\n",
    "\n",
    "    return np.dstack((arr[0], arr[1], arr[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis afin de standardiser nos valeurs, nous décidons de redistribuer nos valeurs entre 0 et 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleChannel(image, sig, vrange):\n",
    "    \"\"\"Perform action in a single channel of an image\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : array-like, shape (width, height, channel)\n",
    "        Data\n",
    "    sig : int\n",
    "        Standard deviation\n",
    "    vrange : array-like, shape (minus, plus)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Image processed\n",
    "    \"\"\"\n",
    "    \n",
    "    blurred = ndimage.gaussian_filter(image, sigma=sig, mode='reflect') #apply gaussian filter\n",
    "    result = image + (image - blurred) * 1\n",
    "    if vrange is not None:\n",
    "        return np.clip(result, vrange[0], vrange[1], out=result) #Given an interval, values outside the interval are clipped to the interval edges. For example, if an interval of [0, 1] is specified, values smaller than 0 become 0, and values larger than 1 become 1.\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout comme la phase de test précédente les résultats ne nous convenaient pas, car certaines valeurs étaient aberrantes.\n",
    "\n",
    "## Solution\n",
    "\n",
    "### Explication\n",
    "\n",
    "Dans cette partie, nous avons utilisé la bibliothèque Scikit-image.\n",
    "\n",
    "### Processus\n",
    "\n",
    "Pour résoudre les problèmes de flou et de bruit, nous utilisons la fonction unsharp_mask de skimage.filters.\n",
    "Celle-ci réalise deux processus:\n",
    "<ol>\n",
    "<li>Elle applique un filtre gaussien afin de lisser l'image. </li>\n",
    "<li>Puis elle applique la même matrice que précédemment afin d'améliorer la netteté de l'image $$\\begin{bmatrix} -1 & -1 & -1 \\\\ -1 & 9 & -1 \\\\ -1 & -1 & -1 \\end{bmatrix}$$</li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "Dans un second temps la formule suivante est appliquée : \n",
    "\n",
    "$$enhanced Image = original + amount * (original - blurred)$$\n",
    "\n",
    "$amount$ correspond à l'amplification des détails de l'image, plus celui-ci est élevé, plus les contrastes sont élevés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_noisy(collection):\n",
    "    \"\"\"Process noisy image\n",
    "    Parameters\n",
    "    ----------\n",
    "    collection : array-like, shape (file)\n",
    "        Data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    for file in range(len(collection)):\n",
    "        result = unsharp_mask(collection[file], radius=1, amount=1)\n",
    "        noisyPost.append(result)\n",
    "        imsave('noisyEnd/' + collection.files[file][-7:-4] + '.jpg', img_as_ubyte(result))\n",
    "    return 1\n",
    "        \n",
    "def process_blurry(collection):\n",
    "    \"\"\"Process blurry image\n",
    "    Parameters\n",
    "    ----------\n",
    "    collection : array-like, shape (file)\n",
    "        Data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    for file in range(len(collection)):\n",
    "        result = unsharp_mask(collection[file], radius=0, amount=1)\n",
    "        blurryPost.append(result)\n",
    "        imsave('blurryEnd/' + collection.files[file][-7:-4] + '.jpg', img_as_ubyte(result))\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_noisy(noisy)\n",
    "#process_blurry(blurry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indice de performance\n",
    "\n",
    "### Images bruitées\n",
    "\n",
    "Dans cette partie de notre traitement, le but est de prouver l'efficacité de notre traitement d'image.\n",
    "\n",
    "Pour se faire nous avons utilisé la fonction estimate_sigma() de la biliothèque scikit-image. \n",
    "\n",
    "Cette fonction permet d'estimer l'écart-type de la fonction de Gauss. Puis nous faisons une moyenne de tous les écarts types des images de base et une moyenne des écarts type des images traitées. Enfin, elle détermine le taux de variation entre les deux moyennes obtenues. La fonction nous renvoie un résultat avoisinant les 40%, ce qui signifie que la fonction pour atténuer le bruit est performante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.91\n"
     ]
    }
   ],
   "source": [
    "# Get the Denoised images\n",
    "noisyTreated = imread_collection('noisyEnd/*.jpg')\n",
    "\n",
    "def estimate_noise(listNoise, listDeNoise):\n",
    "    \"\"\"Calculates noise rates in an image\n",
    "    Parameters\n",
    "    ----------\n",
    "    listNoise : array-like, shape (file)\n",
    "        Data\n",
    "    listDeNoise: array-like, shape (file)\n",
    "        Data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Sigma is the mean rate of noise\n",
    "        \n",
    "    \"\"\"\n",
    "    listSigmaNoise = []\n",
    "    listSigmaDenoise = []\n",
    "    # Get the noise sigma of each image then add it to the list\n",
    "    for imageNoise in listNoise:\n",
    "        sigmaNoise = estimate_sigma(imageNoise, multichannel=True, average_sigmas=True)\n",
    "        listSigmaNoise.append(sigmaNoise)\n",
    "    \n",
    "    # Calculation of the mean sigma of the noised images\n",
    "    totalSigmaNoise = sum(listSigmaNoise)\n",
    "    meanSigmaNoise = totalSigmaNoise/len(listNoise)\n",
    "    \n",
    "    # Same action here for denoised images\n",
    "    for imageDenoise in listDeNoise:\n",
    "        sigmaDenoise = estimate_sigma(imageDenoise, multichannel=True, average_sigmas=True)\n",
    "        listSigmaDenoise.append(sigmaDenoise)\n",
    "\n",
    "    totalSigmaDenoise = sum(listSigmaDenoise)\n",
    "    meanSigmaDenoise = totalSigmaDenoise/len(listDeNoise)\n",
    "\n",
    "    return(meanSigmaNoise,meanSigmaDenoise)\n",
    "\n",
    "# Calculation of the percentage difference between the sigma to obtain the performance index\n",
    "meanSigmaNoise,meanSigmaDenoise = estimate_noise(noisy,noisyTreated)\n",
    "performance_index_noisy = ((meanSigmaDenoise - meanSigmaNoise)/meanSigmaNoise)*100\n",
    "print(round(performance_index_noisy,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images floutées\n",
    "\n",
    "Pour connaître la performance de notre processus, nous avons dû détecter le flou dans notre image originale. Pour cela, nous utilisons la variance de Laplace grâce à « cv2.Laplacian(collectionPre[file], cv2.CV_64F).var() ». Plus le résultat est proche de 0, plus l’image est floutée. Donc nous l’appliquons sur notre image de base puis sur notre image après traitement et nous ajoutons ces données dans un dataframe pour que cela soit plus lisible et exploitable par la suite. Comme vous pouvez le voir le résultat de la fonction appliquée aux images post-traitement est proche de zéro, ce qui montre que le traitement est un succès."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blurryDetection(collectionPre, collectionPost): \n",
    "    \"\"\"Calculates blur rate in an image\n",
    "    Parameters\n",
    "    ----------\n",
    "    collectionPre : array-like, shape (file)\n",
    "        Data\n",
    "    collectionPost: array-like, shape (file)\n",
    "        Data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dataframe with the comparison of detection before and after treatment\n",
    "        \n",
    "    \"\"\"\n",
    "    Df= pd.DataFrame(columns=['FileName','Blur rate pre-treatment','Blur rate post-treatment'])\n",
    "    for file in range(len(collectionPre)):\n",
    "        imagePre = cv2.Laplacian(collectionPre[file], cv2.CV_64F).var()\n",
    "        imagePost = cv2.Laplacian(collectionPost[file], cv2.CV_64F).var()\n",
    "        Df=Df.append({'FileName':collectionPre.files[file],'Blur rate pre-treatment':imagePre,'Blur rate post-treatment':imagePost},ignore_index=True)\n",
    "    print(\"Max_traitement : \",\"\\n\", Df[ Df['Blur rate post-treatment'] == Df['Blur rate post-treatment'].max() ],\"\\n\")\n",
    "    print(\"Min_traitement : \",\"\\n\",Df[ Df['Blur rate post-treatment'] == Df['Blur rate post-treatment'].min() ],\"\\n\")\n",
    "    print(\"Variance_After_traitement : \", Df['Blur rate post-treatment'].var() ,\"\\n\")\n",
    "    print(\"Mean_After_traitement : \", Df['Blur rate post-treatment'].mean() ,\"\\n\")\n",
    "    return Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Blur rate pre-treatment</th>\n",
       "      <th>Blur rate post-treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blurry\\blurry_001.jpg</td>\n",
       "      <td>417.029056</td>\n",
       "      <td>0.006413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blurry\\blurry_002.jpg</td>\n",
       "      <td>65.037823</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blurry\\blurry_003.jpg</td>\n",
       "      <td>607.788792</td>\n",
       "      <td>0.009347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blurry\\blurry_004.jpg</td>\n",
       "      <td>245.151501</td>\n",
       "      <td>0.003770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blurry\\blurry_005.jpg</td>\n",
       "      <td>227.685810</td>\n",
       "      <td>0.003502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Blurry\\blurry_146.jpg</td>\n",
       "      <td>137.893416</td>\n",
       "      <td>0.002121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Blurry\\blurry_147.jpg</td>\n",
       "      <td>262.208983</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Blurry\\blurry_148.jpg</td>\n",
       "      <td>89.037813</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Blurry\\blurry_149.jpg</td>\n",
       "      <td>112.238551</td>\n",
       "      <td>0.001726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Blurry\\blurry_150.jpg</td>\n",
       "      <td>198.452992</td>\n",
       "      <td>0.003052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FileName  Blur rate pre-treatment  Blur rate post-treatment\n",
       "0    Blurry\\blurry_001.jpg               417.029056                  0.006413\n",
       "1    Blurry\\blurry_002.jpg                65.037823                  0.001000\n",
       "2    Blurry\\blurry_003.jpg               607.788792                  0.009347\n",
       "3    Blurry\\blurry_004.jpg               245.151501                  0.003770\n",
       "4    Blurry\\blurry_005.jpg               227.685810                  0.003502\n",
       "..                     ...                      ...                       ...\n",
       "145  Blurry\\blurry_146.jpg               137.893416                  0.002121\n",
       "146  Blurry\\blurry_147.jpg               262.208983                  0.004032\n",
       "147  Blurry\\blurry_148.jpg                89.037813                  0.001369\n",
       "148  Blurry\\blurry_149.jpg               112.238551                  0.001726\n",
       "149  Blurry\\blurry_150.jpg               198.452992                  0.003052\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blurryDetection(blurry, blurryPost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
